# -*- coding: utf-8 -*-
"""Time_Series_LSTM (function)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UYkbNKPUcrm1JB341R4ob_-yFLw55lhL
"""

# Importamos librerias necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, Input
from sklearn.metrics import mean_squared_error
import math
from keras import callbacks

from google.colab import drive
drive.mount('/content/drive')

# Cargamos el dataset
# raw_data = pd.read_csv('/content/drive/MyDrive/Projecto Marvik/Datos/TWTR.csv')
# raw_data = pd.read_csv('/content/drive/MyDrive/Projecto Marvik/Datos/META.csv')
raw_data = pd.read_csv('/content/drive/MyDrive/Projecto Marvik/Datos/S&P500.csv') # sacado de NASDAQ

def run_model(raw_data, lag, lstm_neurons, epochs):

  # Nos quedamos solamente con el valor de cierre de la accion
  raw_data = raw_data[['Close']]

  # Normalizamos el dataset
  dataset = raw_data.values
  dataset = dataset.astype('float32')
  scaler = MinMaxScaler(feature_range=(0, 1))
  dataset = scaler.fit_transform(dataset)

  # Funcion para crear el dataset que le vamos a pasar al modelo, teniendo en cuenta el lag
  def create_dataset(dataset, lag):
      dataX, dataY = np.zeros((len(dataset)-lag,lag)), np.zeros(len(dataset)-lag)
      for i in range(len(dataset)-lag):
          dataX[i,:] = dataset[i:i+lag,0]
          dataY[i] = dataset[i+lag,0]
      return dataX, dataY

  # Ejecutamos la funcion de create_dataset y establecemos el lag
  datasetX, datasetY = create_dataset(dataset, lag)

  # Separamos el dataset en train y test
  train_size = int(len(datasetX) * 0.67)
  test_size = len(datasetX) - train_size
  trainX, testX = datasetX[0:train_size,:], datasetX[train_size:len(dataset),:]
  trainY, testY = datasetY[0:train_size], datasetY[train_size:len(dataset)]

  # Agregamos una dimensión para poder pasarle luego al modelo
  trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
  testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

  # Capas y armado del modelo
  model = Sequential([LSTM(lstm_neurons, input_shape=(1, trainX.shape[2])),
                      Dense(lstm_neurons/2, activation='relu'),
                      Dense(lstm_neurons/2, activation='relu'),
                      Dense(1)])

  # Seleccion de metricas y entrenamiento del modelo
  model.compile(loss='mean_squared_error', optimizer='adam', metrics= "MeanSquaredError")
  
  # Recupera los mejores weights que el modelo encontro en todas las corridas
  earlystopping = callbacks.EarlyStopping(monitor="val_loss", mode="min", patience=10, restore_best_weights=True)
  
  model.fit(trainX, trainY, batch_size=1, epochs=epochs, verbose=1, validation_split=0.1, callbacks=[earlystopping])

  score = model.evaluate(testX, testY, verbose = 1)

  # Hacemos las predicciones
  trainPredict = model.predict(trainX)
  testPredict = model.predict(testX)

  # Invertimos la normalizacion de los datos para poder calcular el RMSE
  trainPredict = scaler.inverse_transform(trainPredict)
  trainY = scaler.inverse_transform([trainY])
  testPredict = scaler.inverse_transform(testPredict)
  testY = scaler.inverse_transform([testY])

  # Usamos el RMSE como métrica para evaluar la eficiencia del modelo
  # Train Score
  trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
  # Test Score
  testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))

  # Creamos nuevos datasets para graficar las predicciones
  # Train
  trainPredictPlot = np.empty_like(dataset)
  trainPredictPlot[:, :] = np.nan
  trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict

  # Test
  testPredictPlot = np.empty_like(dataset)
  testPredictPlot[:, :] = np.nan
  testPredictPlot[len(trainPredict)+lag:, :] = testPredict

  original_dataset = scaler.inverse_transform(dataset)

  return (trainScore , testScore, original_dataset, trainPredictPlot, testPredictPlot)

# Una corrida
raw_data = raw_data
lstm_neurons = 64
epochs = 20
lag = 1

trainScore , testScore, original_dataset, trainPredictPlot, testPredictPlot = \
run_model(raw_data, lag, lstm_neurons, epochs)

# Graficamos
plt.figure(figsize=(20,7))
plt.plot(original_dataset[-600:])
plt.plot(trainPredictPlot[-600:])
plt.plot(testPredictPlot[-600:])
plt.legend(['Original Time Series','trainPredictPlot','testPredictPlot'])
plt.show()

# Prueba con diferentes lags para hallar el numero optimo en base al RMSE
raw_data = raw_data
lstm_neurons = 64
epochs = 5
lags = range(1,11)

RMSE = [run_model(raw_data, lag, lstm_neurons, epochs) for lag in lags]

# Nos quedamos con el train y test score (RMSE)
train, test = [], []
for i, j, k, l, m in RMSE:
  train.append(i)
  test.append(j)

plt.plot(lags, train, c='b', alpha=0.75)
plt.plot(lags, test, c='r', alpha=0.75)
plt.title('Train/Test Data')
plt.ylabel('RMSE')
plt.xlabel('Lag')
plt.legend(['Train','Test'])
# plt.ylim(ymin=1.1,ymax=2.3)
plt.xticks(range(1,11))
plt.show()
print('Numero optimo de lags en train: ' + str(train.index(min(train))+1))
print('Numero optimo de lags en test: ' + str(test.index(min(test))+1))

